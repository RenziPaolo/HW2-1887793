{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"CDVJcVjPK-jp"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","import torch\n","import pickle\n","from torch.utils.data import DataLoader\n","from datasets import load_dataset\n","from transformers import DataCollatorWithPadding\n","from src.base_model import BaseModel\n","from src.KAN_model import KANModel\n","from src.Mixed_model import MIXEDModel\n","from src.Augement import Augment\n","from src.trainer import TrainerCustom\n","from src.dataset import TextDataset\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    Trainer,\n","    TrainingArguments,\n","    set_seed,\n",")\n","\n","\n","### Model Parameters\n","# we will use with Distil-BERT\n","language_model_name = \"distilbert-base-uncased\"\n","length = 32\n","\n","save_path = './data/processed_dataset.pkl'\n","\n","### Training Argurments\n","\n","# batch\n","batch_size = 128\n","\n","# optim\n","learning_rate = 1e-7\n","weight_decay = 0.01 # we could use e.g. 0.01 in case of very low and very high amount of data for regularization\n","\n","# training\n","epochs = 10\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","\n","set_seed(42)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def append_update(d1, d2):\n","    for key, value in d2.items():\n","        if key in d1:\n","            if isinstance(d1[key], list):\n","                d1[key].append(value)\n","            else:\n","                d1[key] = [d1[key], value]\n","        else:\n","            d1[key] = value\n","    return d1\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def save_data(filepath, dataloader):\n","    # Extract dataset from dataloader\n","    dataset = dataloader.dataset\n","    \n","    # Save input_ids, attention_masks, and labels as tensors\n","    torch.save({\n","        'input_ids': torch.stack(dataset.input_ids),\n","        'attention_masks': torch.stack(dataset.attention_masks),\n","        'labels': dataset.labels\n","    }, filepath)\n","\n","def load_data(filepath, batch_size=32, shuffle=True, num_workers=0):\n","    # Load the data\n","    saved_data = torch.load(filepath)\n","    \n","    # Create a list of tokenized texts\n","    tokenized_texts = [{'input_ids': input_id, 'attention_mask': attention_mask, 'labels': label.squeeze()} \n","                       for input_id, attention_mask, label in zip(saved_data['input_ids'], saved_data['attention_masks'], saved_data['labels'])]\n","    \n","    # Recreate the dataset\n","    dataset = TextDataset(tokenized_texts)\n","    \n","    # Recreate the dataloader\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n","    \n","    return dataloader"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6887,"status":"ok","timestamp":1716454815232,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"1rFUoPr5DS50","outputId":"da3f8566-37f1-40ed-9964-f6c068c3d460"},"outputs":[],"source":["# load our dataset\n","dataset = load_dataset(\"tommasobonomo/sem_augmented_fever_nli\", cache_dir=\"../data/sem_augmented_fever\", trust_remote_code=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716454815232,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"8yvWohoaDVKs","outputId":"fcb403f0-544e-438d-9cfa-f0b28c9ca5bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: {'id': '65960', 'premise': 'Whoopi Goldberg . From 1998 to 2002 , she was co-producer of the television game show Hollywood Squares .', 'hypothesis': 'Whoopi Goldberg co-produced an American dance tournament.', 'label': 'NEUTRAL', 'wsd': {'premise': [{'index': 0, 'text': 'Whoopi', 'pos': 'PROPN', 'lemma': 'Whoopi', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 1, 'text': 'Goldberg', 'pos': 'PROPN', 'lemma': 'Goldberg', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 2, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 3, 'text': 'From', 'pos': 'ADP', 'lemma': 'from', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 4, 'text': '1998', 'pos': 'NUM', 'lemma': '1998', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 5, 'text': 'to', 'pos': 'ADP', 'lemma': 'to', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 6, 'text': '2002', 'pos': 'NUM', 'lemma': '2002', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 7, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 8, 'text': 'she', 'pos': 'PRON', 'lemma': 'she', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 9, 'text': 'was', 'pos': 'AUX', 'lemma': 'be', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 10, 'text': 'co', 'pos': 'NOUN', 'lemma': 'co', 'bnSynsetId': 'bn:00020105n', 'wnSynsetOffset': '9957013n', 'nltkSynset': 'conscientious_objector.n.01'}, {'index': 11, 'text': '-', 'pos': 'NOUN', 'lemma': '-', 'bnSynsetId': 'bn:00018345n', 'wnSynsetOffset': '9917593n', 'nltkSynset': 'child.n.01'}, {'index': 12, 'text': 'producer', 'pos': 'NOUN', 'lemma': 'producer', 'bnSynsetId': 'bn:00064581n', 'wnSynsetOffset': '10480018n', 'nltkSynset': 'producer.n.02'}, {'index': 13, 'text': 'of', 'pos': 'ADP', 'lemma': 'of', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 14, 'text': 'the', 'pos': 'DET', 'lemma': 'the', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 15, 'text': 'television', 'pos': 'NOUN', 'lemma': 'television', 'bnSynsetId': 'bn:00076373n', 'wnSynsetOffset': '6277280n', 'nltkSynset': 'television.n.01'}, {'index': 16, 'text': 'game', 'pos': 'NOUN', 'lemma': 'game', 'bnSynsetId': 'bn:00037182n', 'wnSynsetOffset': '430606n', 'nltkSynset': 'game.n.03'}, {'index': 17, 'text': 'show', 'pos': 'VERB', 'lemma': 'show', 'bnSynsetId': 'bn:00086557v', 'wnSynsetOffset': '2148788v', 'nltkSynset': 'show.v.01'}, {'index': 18, 'text': 'Hollywood', 'pos': 'PROPN', 'lemma': 'Hollywood', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 19, 'text': 'Squares', 'pos': 'PROPN', 'lemma': 'Squares', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 20, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}], 'hypothesis': [{'index': 0, 'text': 'Whoopi', 'pos': 'PROPN', 'lemma': 'Whoopi', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 1, 'text': 'Goldberg', 'pos': 'PROPN', 'lemma': 'Goldberg', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 2, 'text': 'co', 'pos': 'VERB', 'lemma': 'co', 'bnSynsetId': 'bn:00099915a', 'wnSynsetOffset': '1326415a', 'nltkSynset': 'co-ed.s.01'}, {'index': 3, 'text': '-', 'pos': 'VERB', 'lemma': '-', 'bnSynsetId': 'bn:00083181v', 'wnSynsetOffset': '2604760v', 'nltkSynset': 'be.v.01'}, {'index': 4, 'text': 'produced', 'pos': 'VERB', 'lemma': 'produce', 'bnSynsetId': 'bn:00084094v', 'wnSynsetOffset': '2157100v', 'nltkSynset': 'produce.v.06'}, {'index': 5, 'text': 'an', 'pos': 'DET', 'lemma': 'an', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 6, 'text': 'American', 'pos': 'ADJ', 'lemma': 'american', 'bnSynsetId': 'bn:00096963a', 'wnSynsetOffset': '2927512a', 'nltkSynset': 'american.a.01'}, {'index': 7, 'text': 'dance', 'pos': 'NOUN', 'lemma': 'dance', 'bnSynsetId': 'bn:00025142n', 'wnSynsetOffset': '7020538n', 'nltkSynset': 'dance.n.01'}, {'index': 8, 'text': 'tournament', 'pos': 'NOUN', 'lemma': 'tournament', 'bnSynsetId': 'bn:00077750n', 'wnSynsetOffset': '7464725n', 'nltkSynset': 'tournament.n.01'}, {'index': 9, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}]}, 'srl': {'premise': {'tokens': [{'index': 0, 'rawText': 'Whoopi'}, {'index': 1, 'rawText': 'Goldberg'}, {'index': 2, 'rawText': '.'}, {'index': 3, 'rawText': 'From'}, {'index': 4, 'rawText': '1998'}, {'index': 5, 'rawText': 'to'}, {'index': 6, 'rawText': '2002'}, {'index': 7, 'rawText': ','}, {'index': 8, 'rawText': 'she'}, {'index': 9, 'rawText': 'was'}, {'index': 10, 'rawText': 'co'}, {'index': 11, 'rawText': '-'}, {'index': 12, 'rawText': 'producer'}, {'index': 13, 'rawText': 'of'}, {'index': 14, 'rawText': 'the'}, {'index': 15, 'rawText': 'television'}, {'index': 16, 'rawText': 'game'}, {'index': 17, 'rawText': 'show'}, {'index': 18, 'rawText': 'Hollywood'}, {'index': 19, 'rawText': 'Squares'}, {'index': 20, 'rawText': '.'}], 'annotations': [{'tokenIndex': 9, 'verbatlas': {'frameName': 'COPULA', 'roles': [{'role': 'Time', 'score': 1.0, 'span': [3, 7]}, {'role': 'Theme', 'score': 1.0, 'span': [8, 9]}, {'role': 'Attribute', 'score': 1.0, 'span': [10, 20]}]}, 'englishPropbank': {'frameName': 'be.01', 'roles': [{'role': 'ARGM-TMP', 'score': 1.0, 'span': [3, 7]}, {'role': 'ARG1', 'score': 1.0, 'span': [8, 9]}, {'role': 'ARG2', 'score': 1.0, 'span': [10, 20]}]}}]}, 'hypothesis': {'tokens': [{'index': 0, 'rawText': 'Whoopi'}, {'index': 1, 'rawText': 'Goldberg'}, {'index': 2, 'rawText': 'co'}, {'index': 3, 'rawText': '-'}, {'index': 4, 'rawText': 'produced'}, {'index': 5, 'rawText': 'an'}, {'index': 6, 'rawText': 'American'}, {'index': 7, 'rawText': 'dance'}, {'index': 8, 'rawText': 'tournament'}, {'index': 9, 'rawText': '.'}], 'annotations': [{'tokenIndex': 4, 'verbatlas': {'frameName': 'MOUNT_ASSEMBLE_PRODUCE', 'roles': [{'role': 'Agent', 'score': 1.0, 'span': [0, 2]}, {'role': 'Attribute', 'score': 1.0, 'span': [2, 3]}, {'role': 'Product', 'score': 1.0, 'span': [5, 9]}]}, 'englishPropbank': {'frameName': 'produce.01', 'roles': [{'role': 'ARG0', 'score': 1.0, 'span': [0, 2]}, {'role': 'ARGM-MNR', 'score': 1.0, 'span': [2, 3]}, {'role': 'ARG1', 'score': 1.0, 'span': [5, 9]}]}}]}}}\n"]}],"source":["## Let's see an example...\n","print(f\"Sentence: {dataset['train'][12]}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1716454815232,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"fb4h4PlNDcNl","outputId":"df0748eb-8f14-4b46-bcc3-7ee7ed2dadb9"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n","        num_rows: 51086\n","    })\n","    validation: Dataset({\n","        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n","        num_rows: 2288\n","    })\n","    test: Dataset({\n","        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n","        num_rows: 2287\n","    })\n","})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["## The structure of the huggingface dataset.\n","dataset"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["'\\naugemnter = Augment(dataset, \"test\")\\naugmented_dataset =  augemnter.apply()\\naugmented_dataset\\n'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","augemnter = Augment(dataset, \"test\")\n","augmented_dataset =  augemnter.apply()\n","augmented_dataset\n","'''"]},{"cell_type":"markdown","metadata":{"id":"5zxaIw4Zljkn"},"source":["### Metric Definition\n","\n","Looking only at cross entropy loss cannot allow us to understand effectively the real capabilities of our NLP model. So let's define a standard method to compute:\n","\n","- **Accuracy** metric\n","- **F1** metric"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"UnQC7RJhJU1l"},"outputs":[],"source":["from datasets import load_metric\n","\n","# Metrics\n","\n","def compute_metrics(eval_pred):\n","   load_accuracy = load_metric(\"accuracy\")\n","   load_f1 = load_metric(\"f1\")\n","\n","   logits, labels = eval_pred\n","   predictions = np.argmax(logits, axis=-1)\n","   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n","   f1 = load_f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n","   return {\"accuracy\": accuracy, \"f1\": f1}"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2024,"status":"ok","timestamp":1716454868624,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"BaeWJQhKtZ1H","outputId":"09c9c6b7-17af-48f8-bf0a-a5b577bb3ef4"},"outputs":[],"source":["## Initialize the model\n","\n","MIXED_model = MIXEDModel(length, language_model_name, device)\n","'''\n","KAN_model = KANModel(length, language_model_name, device)\n","auto_model = AutoModelForSequenceClassification.from_pretrained(language_model_name,\n","                                                                   ignore_mismatched_sizes=True,\n","                                                                   output_attentions=False, output_hidden_states=False,\n","                                                                   num_labels=3) # number of the classes\n","base_model = BaseModel(device, length, language_model_name)\n","\n","'''\n","tokenizer = AutoTokenizer.from_pretrained(language_model_name)\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","def tokenize_function(examples):\n","    label_map = {\n","        'ENTAILMENT': 0,\n","        'CONTRADICTION': 1,\n","        'NEUTRAL': 2\n","    }\n","    # Map the labels\n","    examples['label'] = [label_map[label] for label in examples['label']]\n","    \n","    # Tokenize the premise and hypothesis\n","    \n","    tokenized = tokenizer(\n","        examples['premise'], \n","        examples['hypothesis'], \n","        truncation=True, \n","        padding='max_length',\n","        max_length=length\n","    )\n","    \n","    # Add tokenized fields to the examples\n","    examples.update(tokenized)\n","    return examples"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def tokenize_sense_function(examples):\n","    #TODO add word sense\n","    label_map = {\n","        'ENTAILMENT': 0,\n","        'CONTRADICTION': 1,\n","        'NEUTRAL': 2\n","    }\n","    # Map the labels\n","    examples['label'] = [label_map[label] for label in examples['label']]\n","    \n","    # Tokenize the premise and hypothesis\n","    tokenized = tokenizer(\n","        examples['premise'], \n","        examples['hypothesis'], \n","        truncation=True, \n","        padding='max_length',\n","        max_length=length\n","    )\n","    \n","    # Add tokenized fields to the examples\n","    examples.update(tokenized)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["a57be2faae5d45638af3e44a914b51a4","89aafc0136e24694ba6463efb9750dee","b8aa45fb144e435a86512dc9a08850c7","bd361e230d604ea68cf0d6e5811cf727","07953d4ddf8f4fc3b0983adf6b32e2df","2674353de1af46028f3a996d7bd139c6","91cbb2a7875f46f9851c140a73cc3d63","32b8138813054c1dbbc9ffcfae09a956","804240cff4aa45c0a58ffaf623bd47e0","f94aa52c201743d2996a6cd8366faf96","2173a807b5224232bc0ec1293597e077"]},"executionInfo":{"elapsed":636,"status":"ok","timestamp":1716454869253,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"KwXqj8tct-yD","outputId":"90f27219-e611-4039-9ddf-3f096e59ad5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n","        num_rows: 51086\n","    })\n","    validation: Dataset({\n","        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n","        num_rows: 2288\n","    })\n","    test: Dataset({\n","        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n","        num_rows: 2287\n","    })\n","})\n"]}],"source":["# Tokenize the dataset put the second phrase as the second parameter to have it concatenated with a <SEP> token\n","\n","'''\n","print(\"Tokenize the dataset ...\")\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","tokenized_sense_dataset = dataset.map(tokenize_sense_function, batched=True)\n","tokenized_augmented_dataset = augmented_dataset.map(tokenize_function, batched=True)\n","tokenized_augmented_sense_dataset = augmented_dataset.map(tokenize_sense_function, batched=True)\n","'''\n","print(dataset)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["\"\\nprint(tokenized_dataset['train'][1].keys())\\nprint(tokenized_dataset['train'][1]['label'])\\nprint(tokenized_dataset['train'][1]['input_ids'])\\n\""]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","print(tokenized_dataset['train'][1].keys())\n","print(tokenized_dataset['train'][1]['label'])\n","print(tokenized_dataset['train'][1]['input_ids'])\n","'''"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loading train ...\n","loading validation ...\n","loading test ...\n"]}],"source":["splits = ['train', 'validation', 'test']\n","KAN_dataset = {'train':[], 'validation': [], 'test':[]}\n","\n","for split in splits:\n","    if os.path.isfile(save_path[:-4]+split+str(length)+save_path[-4:]):\n","        print('loading',split,'...')\n","        KAN_dataset[split] = load_data(save_path[:-4]+split+str(length)+save_path[-4:], batch_size=batch_size, num_workers=0)\n","    else:\n","        print('generating',split,'...')\n","        i = 0\n","        for data in dataset[split]:\n","            tokens = tokenizer(\n","                    data['premise'], \n","                    data['hypothesis'], \n","                    truncation=True, \n","                    padding='max_length',\n","                    max_length=length,\n","                    return_tensors='pt'\n","                    ).to(device)\n","            label_map = {\n","            'ENTAILMENT': 0,\n","            'CONTRADICTION': 1,\n","            'NEUTRAL': 2\n","            }\n","            # Map the labels\n","            label = label_map[data['label']]\n","\n","            tokens.update({'labels': torch.tensor(label).unsqueeze(0).to(device)})\n","            KAN_dataset[split].append(tokens)\n","            i += 1\n","            if not i%1000: print(split,\"step:\",i)\n","        print('saving',split,'...')\n","        tokenized_dataset = TextDataset(KAN_dataset[split])\n","        dataloader = DataLoader(tokenized_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","        save_data(save_path[:-4]+split+str(length)+save_path[-4:], dataloader)\n"]},{"cell_type":"markdown","metadata":{"id":"GWmn_wLzooPe"},"source":["## Model Training\n","\n","To train a transformer model you can rely on the **Trainer** class of Huggingface (https://huggingface.co/docs/transformers/main_classes/trainer).\n","\n","The Trainer class allows you to save many lines of code, and makes your code much more readable.\n","\n","To initialize the Trainer class you have to define a **TrainerArguments** object."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ArBIUUy_vDPg"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"training_dir\",                    # output directory [Mandatory]\n","    num_train_epochs=epochs,                      # total number of training epochs\n","    per_device_train_batch_size=batch_size,       # batch size per device during training\n","    warmup_steps=1000,                             # number of warmup steps for learning rate scheduler\n","    weight_decay=weight_decay,                    # strength of weight decay\n","    save_strategy=\"no\",\n","    learning_rate=learning_rate,                  # learning rate\n","    gradient_checkpointing=True\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"o4rAJRJNucX0"},"outputs":[{"data":{"text/plain":["'\\ntrainer_base = Trainer(\\n   model=base_model,\\n   args=training_args,\\n   train_dataset=tokenized_dataset[\"train\"],\\n   eval_dataset=tokenized_dataset[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics\\n)\\ntrainer_auto = Trainer(\\n   model=auto_model,\\n   args=training_args,\\n   train_dataset=tokenized_dataset[\"train\"],\\n   eval_dataset=tokenized_dataset[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics\\n)\\n\\n\\ntrainer_sense_auto = Trainer(\\n   model=auto_model,\\n   args=training_args,\\n   train_dataset=tokenized_sense_dataset[\"train\"],\\n   eval_dataset=tokenized_sense_dataset[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics\\n)\\n\\ntrainer_sense_base = Trainer(\\n   model=base_model,\\n   args=training_args,\\n   train_dataset=tokenized_sense_dataset[\"train\"],\\n   eval_dataset=tokenized_sense_dataset[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics\\n)\\n\\ntrainer_sense_KAN = Trainer(\\n   model=KAN_model,\\n   args=training_args,\\n   train_dataset=tokenized_sense_dataset[\"train\"],\\n   eval_dataset=tokenized_sense_dataset[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics\\n)\\n'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["trainer_KAN = TrainerCustom(\n","model=MIXED_model,\n","optimizer=torch.optim.Adam(MIXED_model.parameters(), lr=learning_rate,weight_decay=weight_decay),\n","#loss_function=nn.CrossEntropyLoss(),\n","log_steps=10\n",")\n","\n","'''\n","trainer_base = Trainer(\n","   model=base_model,\n","   args=training_args,\n","   train_dataset=tokenized_dataset[\"train\"],\n","   eval_dataset=tokenized_dataset[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics\n",")\n","trainer_auto = Trainer(\n","   model=auto_model,\n","   args=training_args,\n","   train_dataset=tokenized_dataset[\"train\"],\n","   eval_dataset=tokenized_dataset[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics\n",")\n","\n","\n","trainer_sense_auto = Trainer(\n","   model=auto_model,\n","   args=training_args,\n","   train_dataset=tokenized_sense_dataset[\"train\"],\n","   eval_dataset=tokenized_sense_dataset[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics\n",")\n","\n","trainer_sense_base = Trainer(\n","   model=base_model,\n","   args=training_args,\n","   train_dataset=tokenized_sense_dataset[\"train\"],\n","   eval_dataset=tokenized_sense_dataset[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics\n",")\n","\n","trainer_sense_KAN = Trainer(\n","   model=KAN_model,\n","   args=training_args,\n","   train_dataset=tokenized_sense_dataset[\"train\"],\n","   eval_dataset=tokenized_sense_dataset[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics\n",")\n","'''"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218},"executionInfo":{"elapsed":392847,"status":"ok","timestamp":1716455277605,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"8ohc7fZBvjDJ","outputId":"37b419c1-fabf-4624-e6df-3e6e83ab5157"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training ...\n"," Epoch  1\n","\t[E:  1 @ step 0] current avg loss = 1.3335 in 0:00:06.272876\n","\t[E:  1 @ step 10] current avg loss = 1.4147 in 0:01:08.735379\n","\t[E:  1 @ step 20] current avg loss = 1.3827 in 0:02:13.407141\n","\t[E:  1 @ step 30] current avg loss = 1.3740 in 0:03:17.694704\n","\t[E:  1 @ step 40] current avg loss = 1.3522 in 0:04:22.538791\n","\t[E:  1 @ step 50] current avg loss = 1.3378 in 0:05:26.768466\n","\t[E:  1 @ step 60] current avg loss = 1.3285 in 0:06:31.221627\n","\t[E:  1 @ step 70] current avg loss = 1.3147 in 0:07:35.724878\n","\t[E:  1 @ step 80] current avg loss = 1.3090 in 0:08:40.194726\n","\t[E:  1 @ step 90] current avg loss = 1.3074 in 0:09:44.399234\n","\t[E:  1 @ step 100] current avg loss = 1.3113 in 0:10:49.097708\n","\t[E:  1 @ step 110] current avg loss = 1.3093 in 0:11:53.717488\n","\t[E:  1 @ step 120] current avg loss = 1.3062 in 0:12:58.350711\n","\t[E:  1 @ step 130] current avg loss = 1.3030 in 0:14:03.279121\n","\t[E:  1 @ step 140] current avg loss = 1.3045 in 0:15:07.492848\n","\t[E:  1 @ step 150] current avg loss = 1.3009 in 0:16:11.595622\n","\t[E:  1 @ step 160] current avg loss = 1.2980 in 0:17:15.882512\n","\t[E:  1 @ step 170] current avg loss = 1.2951 in 0:18:19.852414\n","\t[E:  1 @ step 180] current avg loss = 1.2921 in 0:19:23.226397\n","\t[E:  1 @ step 190] current avg loss = 1.2882 in 0:20:26.534320\n","\t[E:  1 @ step 200] current avg loss = 1.2859 in 0:21:28.242246\n","\t[E:  1 @ step 210] current avg loss = 1.2826 in 0:22:27.433344\n","\t[E:  1 @ step 220] current avg loss = 1.2808 in 0:23:28.510122\n","\t[E:  1 @ step 230] current avg loss = 1.2796 in 0:24:29.243737\n","\t[E:  1 @ step 240] current avg loss = 1.2768 in 0:25:29.880483\n","\t[E:  1 @ step 250] current avg loss = 1.2753 in 0:26:33.488644\n","\t[E:  1 @ step 260] current avg loss = 1.2731 in 0:27:39.279161\n","\t[E:  1 @ step 270] current avg loss = 1.2696 in 0:28:44.417706\n","\t[E:  1 @ step 280] current avg loss = 1.2682 in 0:29:47.654878\n","\t[E:  1 @ step 290] current avg loss = 1.2668 in 0:30:47.515269\n","\t[E:  1 @ step 300] current avg loss = 1.2648 in 0:31:46.140069\n","\t[E:  1 @ step 310] current avg loss = 1.2644 in 0:32:45.356050\n","\t[E:  1 @ step 320] current avg loss = 1.2628 in 0:33:44.029165\n","\t[E:  1 @ step 330] current avg loss = 1.2603 in 0:34:43.046790\n","\t[E:  1 @ step 340] current avg loss = 1.2567 in 0:35:41.886170\n","\t[E:  1 @ step 350] current avg loss = 1.2553 in 0:36:40.407967\n","\t[E:  1 @ step 360] current avg loss = 1.2538 in 0:37:40.619808\n","\t[E:  1 @ step 370] current avg loss = 1.2513 in 0:38:40.936953\n","\t[E:  1 @ step 380] current avg loss = 1.2490 in 0:39:41.657804\n","\t[E:  1 @ step 390] current avg loss = 1.2485 in 0:40:41.516517\n","\t[E:  1] train loss = 1.2464\n","  [E:  1] valid loss = 1.6776, valid acc = 0.3616\n"," Epoch  2\n","\t[E:  2 @ step 0] current avg loss = 1.1579 in 0:42:04.200330\n","\t[E:  2 @ step 10] current avg loss = 1.2303 in 0:43:05.140735\n","\t[E:  2 @ step 20] current avg loss = 1.2120 in 0:44:05.879113\n","\t[E:  2 @ step 30] current avg loss = 1.2135 in 0:45:06.420370\n","\t[E:  2 @ step 40] current avg loss = 1.2030 in 0:46:06.601312\n","\t[E:  2 @ step 50] current avg loss = 1.2118 in 0:47:06.695024\n","\t[E:  2 @ step 60] current avg loss = 1.1994 in 0:48:06.694304\n","\t[E:  2 @ step 70] current avg loss = 1.1996 in 0:49:06.842061\n","\t[E:  2 @ step 80] current avg loss = 1.1953 in 0:50:06.990374\n","\t[E:  2 @ step 90] current avg loss = 1.1861 in 0:51:06.797215\n","\t[E:  2 @ step 100] current avg loss = 1.1885 in 0:52:05.816215\n","\t[E:  2 @ step 110] current avg loss = 1.1848 in 0:53:03.259785\n","\t[E:  2 @ step 120] current avg loss = 1.1899 in 0:54:00.435995\n","\t[E:  2 @ step 130] current avg loss = 1.1938 in 0:54:57.833818\n","\t[E:  2 @ step 140] current avg loss = 1.1926 in 0:55:55.213423\n","\t[E:  2 @ step 150] current avg loss = 1.1938 in 0:56:53.408884\n","\t[E:  2 @ step 160] current avg loss = 1.1899 in 0:57:54.851212\n","\t[E:  2 @ step 170] current avg loss = 1.1911 in 0:58:56.760787\n","\t[E:  2 @ step 180] current avg loss = 1.1900 in 0:59:58.913428\n","\t[E:  2 @ step 190] current avg loss = 1.1888 in 1:01:00.263920\n","\t[E:  2 @ step 200] current avg loss = 1.1888 in 1:02:02.162809\n","\t[E:  2 @ step 210] current avg loss = 1.1884 in 1:03:04.338084\n","\t[E:  2 @ step 220] current avg loss = 1.1873 in 1:04:07.461686\n","\t[E:  2 @ step 230] current avg loss = 1.1871 in 1:05:11.203555\n","\t[E:  2 @ step 240] current avg loss = 1.1859 in 1:06:16.014873\n","\t[E:  2 @ step 250] current avg loss = 1.1858 in 1:07:19.699610\n","\t[E:  2 @ step 260] current avg loss = 1.1860 in 1:08:18.387651\n","\t[E:  2 @ step 270] current avg loss = 1.1876 in 1:09:15.029865\n","\t[E:  2 @ step 280] current avg loss = 1.1888 in 1:10:11.441443\n","\t[E:  2 @ step 290] current avg loss = 1.1876 in 1:11:06.972563\n","\t[E:  2 @ step 300] current avg loss = 1.1875 in 1:12:03.259776\n","\t[E:  2 @ step 310] current avg loss = 1.1879 in 1:12:58.915328\n","\t[E:  2 @ step 320] current avg loss = 1.1858 in 1:13:54.717990\n","\t[E:  2 @ step 330] current avg loss = 1.1842 in 1:14:50.928865\n","\t[E:  2 @ step 340] current avg loss = 1.1828 in 1:15:47.152190\n","\t[E:  2 @ step 350] current avg loss = 1.1820 in 1:16:43.651799\n","\t[E:  2 @ step 360] current avg loss = 1.1823 in 1:17:39.190744\n","\t[E:  2 @ step 370] current avg loss = 1.1815 in 1:18:32.782553\n","\t[E:  2 @ step 380] current avg loss = 1.1810 in 1:19:26.627268\n","\t[E:  2 @ step 390] current avg loss = 1.1801 in 1:20:19.795213\n","\t[E:  2] train loss = 1.1800\n","  [E:  2] valid loss = 1.6116, valid acc = 0.3644\n"," Epoch  3\n","\t[E:  3 @ step 0] current avg loss = 1.1901 in 1:21:31.896610\n","\t[E:  3 @ step 10] current avg loss = 1.1340 in 1:22:25.242454\n","\t[E:  3 @ step 20] current avg loss = 1.1679 in 1:23:18.562840\n","\t[E:  3 @ step 30] current avg loss = 1.1646 in 1:24:12.212794\n","\t[E:  3 @ step 40] current avg loss = 1.1678 in 1:25:06.081474\n","\t[E:  3 @ step 50] current avg loss = 1.1665 in 1:25:59.310206\n","\t[E:  3 @ step 60] current avg loss = 1.1705 in 1:26:53.067687\n","\t[E:  3 @ step 70] current avg loss = 1.1629 in 1:27:46.326368\n","\t[E:  3 @ step 80] current avg loss = 1.1623 in 1:28:39.775292\n","\t[E:  3 @ step 90] current avg loss = 1.1593 in 1:29:34.057853\n","\t[E:  3 @ step 100] current avg loss = 1.1588 in 1:30:27.550807\n","\t[E:  3 @ step 110] current avg loss = 1.1555 in 1:31:20.824882\n","\t[E:  3 @ step 120] current avg loss = 1.1504 in 1:32:14.429532\n","\t[E:  3 @ step 130] current avg loss = 1.1496 in 1:33:07.363450\n","\t[E:  3 @ step 140] current avg loss = 1.1482 in 1:34:00.925809\n","\t[E:  3 @ step 150] current avg loss = 1.1514 in 1:34:53.956567\n","\t[E:  3 @ step 160] current avg loss = 1.1505 in 1:35:47.225382\n","\t[E:  3 @ step 170] current avg loss = 1.1490 in 1:36:40.499978\n","\t[E:  3 @ step 180] current avg loss = 1.1488 in 1:37:33.802558\n","\t[E:  3 @ step 190] current avg loss = 1.1491 in 1:38:27.231311\n","\t[E:  3 @ step 200] current avg loss = 1.1507 in 1:39:20.383011\n","\t[E:  3 @ step 210] current avg loss = 1.1488 in 1:40:13.888878\n","\t[E:  3 @ step 220] current avg loss = 1.1474 in 1:41:07.493831\n","\t[E:  3 @ step 230] current avg loss = 1.1469 in 1:42:00.969231\n","\t[E:  3 @ step 240] current avg loss = 1.1468 in 1:42:54.215036\n","\t[E:  3 @ step 250] current avg loss = 1.1451 in 1:43:47.068902\n","\t[E:  3 @ step 260] current avg loss = 1.1446 in 1:44:40.339829\n","\t[E:  3 @ step 270] current avg loss = 1.1443 in 1:45:33.076426\n","\t[E:  3 @ step 280] current avg loss = 1.1443 in 1:46:26.327509\n","\t[E:  3 @ step 290] current avg loss = 1.1428 in 1:47:19.881671\n","\t[E:  3 @ step 300] current avg loss = 1.1415 in 1:48:13.229570\n","\t[E:  3 @ step 310] current avg loss = 1.1413 in 1:49:07.032659\n","\t[E:  3 @ step 320] current avg loss = 1.1411 in 1:50:00.712714\n","\t[E:  3 @ step 330] current avg loss = 1.1419 in 1:50:54.057163\n","\t[E:  3 @ step 340] current avg loss = 1.1426 in 1:51:47.304338\n","\t[E:  3 @ step 350] current avg loss = 1.1420 in 1:52:40.696763\n","\t[E:  3 @ step 360] current avg loss = 1.1400 in 1:53:33.270326\n","\t[E:  3 @ step 370] current avg loss = 1.1398 in 1:54:26.265062\n","\t[E:  3 @ step 380] current avg loss = 1.1392 in 1:55:19.587857\n","\t[E:  3 @ step 390] current avg loss = 1.1386 in 1:56:12.947234\n","\t[E:  3] train loss = 1.1379\n","  [E:  3] valid loss = 1.5663, valid acc = 0.3625\n"," Epoch  4\n","\t[E:  4 @ step 0] current avg loss = 1.0654 in 1:57:24.910425\n","\t[E:  4 @ step 10] current avg loss = 1.1164 in 1:58:18.480840\n","\t[E:  4 @ step 20] current avg loss = 1.1156 in 1:59:11.764196\n","\t[E:  4 @ step 30] current avg loss = 1.1127 in 2:00:04.887573\n","\t[E:  4 @ step 40] current avg loss = 1.1135 in 2:00:58.412317\n","\t[E:  4 @ step 50] current avg loss = 1.1179 in 2:01:51.551842\n","\t[E:  4 @ step 60] current avg loss = 1.1256 in 2:02:44.595951\n","\t[E:  4 @ step 70] current avg loss = 1.1239 in 2:03:37.589636\n","\t[E:  4 @ step 80] current avg loss = 1.1192 in 2:04:30.168893\n","\t[E:  4 @ step 90] current avg loss = 1.1182 in 2:05:24.268865\n","\t[E:  4 @ step 100] current avg loss = 1.1149 in 2:06:17.613440\n","\t[E:  4 @ step 110] current avg loss = 1.1169 in 2:07:10.440948\n","\t[E:  4 @ step 120] current avg loss = 1.1210 in 2:08:04.132225\n","\t[E:  4 @ step 130] current avg loss = 1.1208 in 2:09:04.058370\n","\t[E:  4 @ step 140] current avg loss = 1.1175 in 2:10:08.353934\n"]}],"source":["# Let's Train ...\n","trainer_KAN.train(KAN_dataset['train'], KAN_dataset['validation'], epochs=epochs)\n","'''\n","trainer_auto.train()\n","trainer_base.train()\n","\n","trainer_sense_auto.train()\n","trainer_sense_base.train()\n","trainer_sense_KAN.train()\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"elapsed":4377,"status":"ok","timestamp":1716455281959,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"fpvMaurQvktK","outputId":"e46ebbe0-5255-4e67-dc2f-9d95966e6d76"},"outputs":[{"data":{"text/plain":["\"\\nmetrics = trainer_base.evaluate()\\nmetrics = trainer_auto.evaluate()#average='weighted')\\ntrainer_sense_auto.evaluate()\\ntrainer_sense_base.evaluate()\\ntrainer_sense_KAN.evaluate()\\n\""]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluate the model ...\n","#metrics = trainerKAN.evaluate()\n","'''\n","metrics = trainer_base.evaluate()\n","metrics = trainer_auto.evaluate()#average='weighted')\n","trainer_sense_auto.evaluate()\n","trainer_sense_base.evaluate()\n","trainer_sense_KAN.evaluate()\n","'''\n","#print(metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["'\\ntrainer_augmented_auto = Trainer(\\n   model=auto_model,\\n   args=training_args,\\n   train_dataset=tokenized_augmented_datasets[\"train\"],\\n   eval_dataset=tokenized_augmented_datasets[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics,\\n)\\n\\ntrainer_augmented_base = Trainer(\\n   model=base_model,\\n   args=training_args,\\n   train_dataset=tokenized_augmented_datasets[\"train\"],\\n   eval_dataset=tokenized_augmented_datasets[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics,\\n)\\n\\ntrainer_augmented_KAN = Trainer(\\n   model=KAN_model,\\n   args=training_args,\\n   train_dataset=tokenized_augmented_datasets[\"train\"],\\n   eval_dataset=tokenized_augmented_datasets[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics,\\n)\\n\\ntrainer_augmented_sense_auto = Trainer(\\n   model=auto_model,\\n   args=training_args,\\n   train_dataset=tokenized_augmented_sense_datasets[\"train\"],\\n   eval_dataset=tokenized_augmented_sense_datasets[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics,\\n)\\n\\ntrainer_augmented_sense_base = Trainer(\\n   model=base_model,\\n   args=training_args,\\n   train_dataset=tokenized_augmented_sense_datasets[\"train\"],\\n   eval_dataset=tokenized_augmented_sense_datasets[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics,\\n)\\n\\ntrainer_augmented_sense_KAN = Trainer(\\n   model=KAN_model,\\n   args=training_args,\\n   train_dataset=tokenized_augmented_sense_datasets[\"train\"],\\n   eval_dataset=tokenized_augmented_sense_datasets[\"validation\"],\\n   tokenizer=tokenizer,\\n   data_collator=data_collator,\\n   compute_metrics=compute_metrics,\\n)\\n'"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","trainer_augmented_auto = Trainer(\n","   model=auto_model,\n","   args=training_args,\n","   train_dataset=tokenized_augmented_datasets[\"train\"],\n","   eval_dataset=tokenized_augmented_datasets[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics,\n",")\n","\n","trainer_augmented_base = Trainer(\n","   model=base_model,\n","   args=training_args,\n","   train_dataset=tokenized_augmented_datasets[\"train\"],\n","   eval_dataset=tokenized_augmented_datasets[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics,\n",")\n","\n","trainer_augmented_KAN = Trainer(\n","   model=KAN_model,\n","   args=training_args,\n","   train_dataset=tokenized_augmented_datasets[\"train\"],\n","   eval_dataset=tokenized_augmented_datasets[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics,\n",")\n","\n","trainer_augmented_sense_auto = Trainer(\n","   model=auto_model,\n","   args=training_args,\n","   train_dataset=tokenized_augmented_sense_datasets[\"train\"],\n","   eval_dataset=tokenized_augmented_sense_datasets[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics,\n",")\n","\n","trainer_augmented_sense_base = Trainer(\n","   model=base_model,\n","   args=training_args,\n","   train_dataset=tokenized_augmented_sense_datasets[\"train\"],\n","   eval_dataset=tokenized_augmented_sense_datasets[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics,\n",")\n","\n","trainer_augmented_sense_KAN = Trainer(\n","   model=KAN_model,\n","   args=training_args,\n","   train_dataset=tokenized_augmented_sense_datasets[\"train\"],\n","   eval_dataset=tokenized_augmented_sense_datasets[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics,\n",")\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["'\\ntrainer_augmented_auto.train()\\ntrainer_augmented_base.train()\\ntrainer_augmented_KAN.train()\\n\\ntrainer_augmented_sense_auto.train()\\ntrainer_augmented_sense_base.train()\\ntrainer_augmented_sense_KAN.train()\\n'"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# Let's Train ...\n","'''\n","trainer_augmented_auto.train()\n","trainer_augmented_base.train()\n","trainer_augmented_KAN.train()\n","\n","trainer_augmented_sense_auto.train()\n","trainer_augmented_sense_base.train()\n","trainer_augmented_sense_KAN.train()\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["'\\ntrainer_augmented_auto.evaluate()\\ntrainer_augmented_base.evaluate()\\ntrainer_augmented_KAN.evaluate()\\n\\ntrainer_augmented_sense_auto.evaluate()\\ntrainer_augmented_sense_base.evaluate()\\ntrainer_augmented_sense_KAN.evaluate()\\n'"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluate the model ...\n","'''\n","trainer_augmented_auto.evaluate()\n","trainer_augmented_base.evaluate()\n","trainer_augmented_KAN.evaluate()\n","\n","trainer_augmented_sense_auto.evaluate()\n","trainer_augmented_sense_base.evaluate()\n","trainer_augmented_sense_KAN.evaluate()\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def save_kan_model(model, path, max_length, model_name, device):\n","    \"\"\"\n","    Save the KANModel to the specified path.\n","    \n","    Args:\n","    - model (KANModel): The model instance to save.\n","    - path (str): The path to save the model.\n","    - max_length (int): The maximum length used in the model.\n","    - model_name (str): The name of the pretrained model.\n","    - device (str): The device on which the model is loaded.\n","    \"\"\"\n","    # Save the state dictionary\n","    torch.save({\n","        'model_state_dict': model.state_dict(),\n","        'max_length': max_length,\n","        'model_name': model_name,\n","        'device': device\n","    }, path)\n","\n","def load_kan_model(path):\n","    \"\"\"\n","    Load the KANModel from the specified path.\n","    \n","    Args:\n","    - path (str): The path to load the model from.\n","    \n","    Returns:\n","    - KANModel: The loaded model instance.\n","    \"\"\"\n","    checkpoint = torch.load(path)\n","    max_length = checkpoint['max_length']\n","    model_name = checkpoint['model_name']\n","    device = checkpoint['device']\n","    \n","    model = KANModel(max_length=max_length, model_name=model_name, device=device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_kan_model(MIXED_model, \"mixed-lr.pk\", length, language_model_name, device)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1pF6VW7equF-gxKeOnCG6qXhjYna2degw","timestamp":1716546082702},{"file_id":"1abQ4ksp5EU9FA-ibnO4OKV1JlGpxR9SL","timestamp":1682676416498},{"file_id":"1yV8wFHpRRy3y3nnJgK1S4ZNosf7teUrC","timestamp":1653295049649}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07953d4ddf8f4fc3b0983adf6b32e2df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2173a807b5224232bc0ec1293597e077":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2674353de1af46028f3a996d7bd139c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32b8138813054c1dbbc9ffcfae09a956":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"804240cff4aa45c0a58ffaf623bd47e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89aafc0136e24694ba6463efb9750dee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2674353de1af46028f3a996d7bd139c6","placeholder":"​","style":"IPY_MODEL_91cbb2a7875f46f9851c140a73cc3d63","value":"Map: 100%"}},"91cbb2a7875f46f9851c140a73cc3d63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a57be2faae5d45638af3e44a914b51a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_89aafc0136e24694ba6463efb9750dee","IPY_MODEL_b8aa45fb144e435a86512dc9a08850c7","IPY_MODEL_bd361e230d604ea68cf0d6e5811cf727"],"layout":"IPY_MODEL_07953d4ddf8f4fc3b0983adf6b32e2df"}},"b8aa45fb144e435a86512dc9a08850c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_32b8138813054c1dbbc9ffcfae09a956","max":1821,"min":0,"orientation":"horizontal","style":"IPY_MODEL_804240cff4aa45c0a58ffaf623bd47e0","value":1821}},"bd361e230d604ea68cf0d6e5811cf727":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f94aa52c201743d2996a6cd8366faf96","placeholder":"​","style":"IPY_MODEL_2173a807b5224232bc0ec1293597e077","value":" 1821/1821 [00:00&lt;00:00, 4770.56 examples/s]"}},"f94aa52c201743d2996a6cd8366faf96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
